{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Wildfire Data Preprocessing Pipeline\n",
    "\n",
    "This notebook performs comprehensive data preprocessing:\n",
    "1. **Data Validation** - Check schema compliance and data quality\n",
    "2. **Data Cleaning** - Remove outliers, handle missing values, deduplicate\n",
    "3. **CRS Alignment** - Reproject all data to California Albers (EPSG:3310)\n",
    "4. **Spatial Integration** - Create unified spatial grid\n",
    "5. **Summary Statistics** - Generate comprehensive data summaries\n",
    "\n",
    "**Target CRS:** EPSG:3310 (NAD83 / California Albers)  \n",
    "**Reason:** Equal-area projection ideal for California-wide spatial analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Data libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Import our preprocessing modules\n",
    "from validate_and_clean import DataValidator, DataCleaner\n",
    "from align_crs import CRSAligner, SpatialJoiner\n",
    "from summaries import DataSummarizer\n",
    "\n",
    "# Add data_sources to path for config\n",
    "sys.path.append('../data_sources')\n",
    "from config import FIRMS_DATA_DIR, NOAA_DATA_DIR, USGS_DATA_DIR\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úì Environment setup complete\")\n",
    "print(f\"\\nData Directories:\")\n",
    "print(f\"  FIRMS: {FIRMS_DATA_DIR}\")\n",
    "print(f\"  NOAA:  {NOAA_DATA_DIR}\")\n",
    "print(f\"  USGS:  {USGS_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load schema\n",
    "with open('schema.json', 'r') as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "# Display target CRS info\n",
    "target_crs = schema['target_crs']\n",
    "\n",
    "display(HTML(f\"\"\"\n",
    "<h3>Target Coordinate Reference System</h3>\n",
    "<table style='width:100%'>\n",
    "    <tr><td><b>EPSG</b></td><td>{target_crs['epsg']}</td></tr>\n",
    "    <tr><td><b>Name</b></td><td>{target_crs['name']}</td></tr>\n",
    "    <tr><td><b>Units</b></td><td>{target_crs['units']}</td></tr>\n",
    "    <tr><td><b>Reason</b></td><td>{target_crs['reason']}</td></tr>\n",
    "</table>\n",
    "\"\"\"))\n",
    "\n",
    "print(f\"\\nSource CRS:\")\n",
    "print(f\"  FIRMS: {schema['firms']['crs']}\")\n",
    "print(f\"  NOAA:  {schema['noaa']['crs']}\")\n",
    "print(f\"  USGS:  {schema['usgs']['crs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Data Validation and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"   STEP 1: DATA VALIDATION AND CLEANING\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Initialize cleaner\n",
    "cleaner = DataCleaner()\n",
    "\n",
    "# Create output directory\n",
    "cleaned_dir = Path(\"../data/cleaned\")\n",
    "cleaned_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Clean FIRMS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    firms_df = cleaner.clean_firms_data(\n",
    "        input_dir=FIRMS_DATA_DIR,\n",
    "        output_path=cleaned_dir / \"firms_cleaned.parquet\"\n",
    "    )\n",
    "    \n",
    "    # Display sample\n",
    "    display(HTML(\"<h4>Cleaned FIRMS Data Sample:</h4>\"))\n",
    "    display(firms_df.head())\n",
    "    \n",
    "    # Quick stats\n",
    "    print(f\"\\nQuick Stats:\")\n",
    "    print(f\"  Date range: {firms_df['acq_date'].min()} to {firms_df['acq_date'].max()}\")\n",
    "    print(f\"  Confidence levels: {firms_df['confidence'].value_counts().to_dict()}\")\n",
    "    print(f\"  Average brightness: {firms_df['brightness'].mean():.1f}K\")\n",
    "    print(f\"  Total FRP: {firms_df['frp'].sum():.0f} MW\")\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"‚ùå FIRMS cleaning failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Clean NOAA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    noaa_df = cleaner.clean_noaa_data(\n",
    "        input_dir=NOAA_DATA_DIR,\n",
    "        output_path=cleaned_dir / \"noaa_cleaned.parquet\"\n",
    "    )\n",
    "    \n",
    "    # Display sample\n",
    "    display(HTML(\"<h4>Cleaned NOAA Data Sample:</h4>\"))\n",
    "    display(noaa_df.head())\n",
    "    \n",
    "    # Quick stats\n",
    "    print(f\"\\nQuick Stats:\")\n",
    "    print(f\"  Date range: {noaa_df['date'].min()} to {noaa_df['date'].max()}\")\n",
    "    print(f\"  Unique stations: {noaa_df['station'].nunique()}\")\n",
    "    \n",
    "    # Data completeness\n",
    "    weather_vars = ['TMAX', 'TMIN', 'PRCP', 'AWND', 'WSF2', 'WSF5']\n",
    "    completeness = {var: f\"{(~noaa_df[var].isnull()).sum() / len(noaa_df):.1%}\" \n",
    "                   for var in weather_vars if var in noaa_df.columns}\n",
    "    print(f\"  Variable completeness: {completeness}\")\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"‚ùå NOAA cleaning failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Validate USGS DEM Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    valid_tiles = cleaner.validate_usgs_tiles(input_dir=USGS_DATA_DIR)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Found {len(valid_tiles)} valid DEM tiles\")\n",
    "    if valid_tiles:\n",
    "        print(\"\\nValid tiles:\")\n",
    "        for tile in valid_tiles:\n",
    "            print(f\"  ‚Ä¢ {Path(tile).name}\")\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"‚ùå USGS validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: CRS Alignment\n",
    "\n",
    "Reproject all datasets to **EPSG:3310** (NAD83 / California Albers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"   STEP 2: CRS ALIGNMENT\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Initialize aligner\n",
    "aligner = CRSAligner()\n",
    "\n",
    "# Create output directory\n",
    "aligned_dir = Path(\"../data/aligned\")\n",
    "aligned_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Align FIRMS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    firms_aligned = aligner.align_firms(\n",
    "        input_path=str(cleaned_dir / \"firms_cleaned.parquet\"),\n",
    "        output_path=str(aligned_dir / \"firms_aligned.parquet\")\n",
    "    )\n",
    "    \n",
    "    # Visualize spatial distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Original coordinates\n",
    "    axes[0].scatter(firms_aligned.longitude, firms_aligned.latitude, \n",
    "                   c='red', alpha=0.1, s=1)\n",
    "    axes[0].set_title('Original Coordinates (EPSG:4326)')\n",
    "    axes[0].set_xlabel('Longitude')\n",
    "    axes[0].set_ylabel('Latitude')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Projected coordinates\n",
    "    axes[1].scatter(firms_aligned.x, firms_aligned.y, \n",
    "                   c='blue', alpha=0.1, s=1)\n",
    "    axes[1].set_title('Projected Coordinates (EPSG:3310)')\n",
    "    axes[1].set_xlabel('X (meters)')\n",
    "    axes[1].set_ylabel('Y (meters)')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"‚ùå FIRMS alignment failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Prepare NOAA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    noaa_aligned = aligner.align_noaa(\n",
    "        input_path=str(cleaned_dir / \"noaa_cleaned.parquet\"),\n",
    "        output_path=str(aligned_dir / \"noaa_aligned.parquet\")\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå NOAA alignment failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Reproject USGS DEM Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    usgs_aligned_dir = aligned_dir / \"usgs\"\n",
    "    success_count = aligner.align_all_usgs_tiles(\n",
    "        input_dir=USGS_DATA_DIR,\n",
    "        output_dir=str(usgs_aligned_dir)\n",
    "    )\n",
    "    \n",
    "    # Visualize one tile if available\n",
    "    aligned_tiles = list(usgs_aligned_dir.glob('*.tif'))\n",
    "    if aligned_tiles:\n",
    "        print(f\"\\nVisualizing sample tile: {aligned_tiles[0].name}\")\n",
    "        \n",
    "        with rasterio.open(aligned_tiles[0]) as src:\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            show(src, ax=ax, cmap='terrain', title=f'DEM: {aligned_tiles[0].name}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"‚ùå USGS alignment failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Generate Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"   STEP 3: GENERATE DATA SUMMARIES\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "summarizer = DataSummarizer(cleaned_data_dir=str(cleaned_dir))\n",
    "summaries = summarizer.generate_all_summaries(usgs_dir=USGS_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Summary Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summaries\n",
    "if 'firms' in summaries:\n",
    "    display(HTML(\"<h3>FIRMS Summary</h3>\"))\n",
    "    display(summaries['firms'])\n",
    "\n",
    "if 'noaa' in summaries:\n",
    "    display(HTML(\"<h3>NOAA Summary</h3>\"))\n",
    "    display(summaries['noaa'])\n",
    "\n",
    "if 'usgs' in summaries:\n",
    "    display(HTML(\"<h3>USGS Tiles Summary</h3>\"))\n",
    "    display(summaries['usgs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Create Spatial Grid (Optional)\n",
    "\n",
    "Create a unified spatial grid for aggregating all data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    joiner = SpatialJoiner(aligned_data_dir=str(aligned_dir))\n",
    "    \n",
    "    # Create 10km x 10km grid\n",
    "    grid = joiner.create_spatial_grid(cell_size=10000)  # 10km\n",
    "    \n",
    "    # Save grid\n",
    "    grid_path = aligned_dir / \"california_grid_10km.parquet\"\n",
    "    grid.to_parquet(grid_path)\n",
    "    print(f\"\\nüíæ Saved spatial grid: {grid_path}\")\n",
    "    \n",
    "    # Visualize grid\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    grid.plot(ax=ax, facecolor='none', edgecolor='gray', linewidth=0.5)\n",
    "    ax.set_title('California 10km Spatial Grid (EPSG:3310)', fontsize=14)\n",
    "    ax.set_xlabel('X (meters)')\n",
    "    ax.set_ylabel('Y (meters)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Grid creation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what was created\n",
    "print(\"=\"*70)\n",
    "print(\"   PREPROCESSING PIPELINE COMPLETE\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Cleaned data\n",
    "cleaned_files = list(cleaned_dir.glob('*.parquet'))\n",
    "print(\"\\nüìÅ Cleaned Data:\")\n",
    "for f in cleaned_files:\n",
    "    size_mb = f.stat().st_size / (1024**2)\n",
    "    print(f\"  ‚úì {f.name} ({size_mb:.1f} MB)\")\n",
    "\n",
    "# Aligned data\n",
    "aligned_files = list(aligned_dir.glob('*.parquet'))\n",
    "aligned_tifs = list((aligned_dir / 'usgs').glob('*.tif')) if (aligned_dir / 'usgs').exists() else []\n",
    "\n",
    "print(\"\\nüìÅ Aligned Data (EPSG:3310):\")\n",
    "for f in aligned_files:\n",
    "    size_mb = f.stat().st_size / (1024**2)\n",
    "    print(f\"  ‚úì {f.name} ({size_mb:.1f} MB)\")\n",
    "if aligned_tifs:\n",
    "    print(f\"  ‚úì {len(aligned_tifs)} USGS DEM tiles (reprojected)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Ready for analysis and visualization!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "1. **Exploratory Data Analysis**: Analyze temporal and spatial patterns\n",
    "2. **Feature Engineering**: Create ML features from cleaned data\n",
    "3. **Spatial Analysis**: Join fire data with weather and terrain\n",
    "4. **Visualization**: Create maps and dashboards\n",
    "5. **Modeling**: Build wildfire prediction models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
